{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pujaroy280/DATA602Assignment7/blob/main/Puja_Roy_07_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd2QZetSDszc"
      },
      "source": [
        "# **Assignment 7**\n",
        "\n",
        "# **Weeks 8 & 9 - Pandas**\n",
        "* In this homework assignment, you will explore and analyze a public dataset of your choosing. Since this assignment is “open-ended” in nature, you are free to expand upon the requirements below. However, you must meet the minimum requirments as indicated in each section.\n",
        "\n",
        "* You must use Pandas as the **primary tool** to process your data.\n",
        "\n",
        "* The preferred method for this analysis is in a .ipynb file. Feel free to use whichever platform of your choosing.  \n",
        " * https://www.youtube.com/watch?v=inN8seMm7UI (Getting started with Colab).\n",
        "\n",
        "* Your data should need some \"work\", or be considered \"dirty\".  You must show your skills in data cleaning/wrangling.\n",
        "\n",
        "### **Some data examples:**\n",
        "•\thttps://www.data.gov/\n",
        "\n",
        "•\thttps://opendata.cityofnewyork.us/\n",
        "\n",
        "•\thttps://datasetsearch.research.google.com/\n",
        "\n",
        "•\thttps://archive.ics.uci.edu/ml/index.php\n",
        "\n",
        "### **Resources:**\n",
        "\n",
        "•\thttps://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html\n",
        "\n",
        "•\thttps://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html\n",
        "\n",
        "\n",
        "### **Headings or comments**\n",
        "**You are required to make use of comments, or headings for each section.  You must explain what your code is doing, and the results of running your code.**  Act as if you were giving this assignment to your manager - you must include clear and descriptive information for each section.\n",
        "\n",
        "### **You may work as a group or indivdually on this assignment.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW3w6p8rqgxu"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this section, please describe the dataset you are using.  Include a link to the source of this data.  You should also provide some explanation on why you choose this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0PnfMOFzOXz"
      },
      "source": [
        "For this assignment, I am planning to leverage the New York Times Best Sellers Dataset from Kaggle: https://www.kaggle.com/datasets/dhruvildave/new-york-times-best-sellers\n",
        "\n",
        "**Description of Data:** All New York Times Best Sellers List from 2010 to 2019 (10 years)\n",
        "\n",
        "**Dataset updated:**\n",
        "Dec 11, 2020\n",
        "\n",
        "This dataset is interesting because I love reading books that are based in New York. As a New York resident, I enjoy watching shows and reading books based on NY's setting. I want to analyze this dataset to observe which books from New York were top-ranked, the price of books, the weeks that the books were on the list for the best selling, and if the dataset contains the books that I am planning to read over the summer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bp8cdDxDs2t"
      },
      "source": [
        "______________\n",
        "# Data Exploration\n",
        "Import your dataset into your .ipynb, create dataframes, and explore your data.  \n",
        "\n",
        "Include:\n",
        "\n",
        "* Summary statistics means, medians, quartiles,\n",
        "* Missing value information\n",
        "* Any other relevant information about the dataset.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OJmbafkEhhq"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# URL of the CSV file\n",
        "# Fetch raw data from my GitHub profile\n",
        "url = \"https://raw.githubusercontent.com/pujaroy280/DATA602Assignment7/main/bestsellers.csv\"\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "df = pd.read_csv(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0WTKtqozNn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e933491-d781-48f6-935d-d4e149ef7824"
      },
      "source": [
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  published_date      list_name list_name_encoded  rank         isbn13  \\\n",
            "0     2010-01-03  Chapter Books     chapter-books     1  9780316036245   \n",
            "1     2010-01-03  Chapter Books     chapter-books     2  9780439023481   \n",
            "2     2010-01-03  Chapter Books     chapter-books     3  9780439023498   \n",
            "3     2010-01-03  Chapter Books     chapter-books     4  9780763644109   \n",
            "4     2010-01-03  Chapter Books     chapter-books     5  9780385738934   \n",
            "\n",
            "       isbn10                    title  \\\n",
            "0  0316036242         WITCH AND WIZARD   \n",
            "1  0439023483         THE HUNGER GAMES   \n",
            "2  0439023491            CATCHING FIRE   \n",
            "3  0763644102  THE MAGICIAN’S ELEPHANT   \n",
            "4  0385738935                   FALLEN   \n",
            "\n",
            "                                     author  \\\n",
            "0  James Patterson and Gabrielle Charbonnet   \n",
            "1                           Suzanne Collins   \n",
            "2                           Suzanne Collins   \n",
            "3                            Kate DiCamillo   \n",
            "4                               Lauren Kate   \n",
            "\n",
            "                                         description  \\\n",
            "0  One of each, brother and sister, flex their ne...   \n",
            "1  In a dystopian future, a girl fights for survi...   \n",
            "2     The protagonist of \"The Hunger Games\" returns.   \n",
            "3  An orphan in search of his sister follows a fo...   \n",
            "4  Thwarted love among misfits at a Savannah, Ga....   \n",
            "\n",
            "                                  amazon_product_url  price  weeks_on_list  \n",
            "0  https://www.amazon.com/Witch-Wizard-James-Patt...  17.99              1  \n",
            "1  https://www.amazon.com/The-Hunger-Games-Suzann...  17.99             67  \n",
            "2  https://www.amazon.com/Catching-Fire-Hunger-Ga...  17.99             16  \n",
            "3  https://www.amazon.com/The-Magicians-Elephant-...  16.99             15  \n",
            "4  https://www.amazon.com/Fallen-Lauren-Kate/dp/0...  17.99              2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display columns\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIKosR9a4EtU",
        "outputId": "c7d99d33-f24b-4164-a590-6891ac8caaf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['published_date', 'list_name', 'list_name_encoded', 'rank', 'isbn13',\n",
            "       'isbn10', 'title', 'author', 'description', 'amazon_product_url',\n",
            "       'price', 'weeks_on_list'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display summary statistics\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRMAsi9I4D3i",
        "outputId": "f39e36b4-990c-4182-8cce-603eee82e30e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               rank         price  weeks_on_list\n",
            "count  61430.000000  61430.000000   61430.000000\n",
            "mean       3.000000      3.863068      24.706267\n",
            "std        1.414225      8.789769      63.534314\n",
            "min        1.000000      0.000000       0.000000\n",
            "25%        2.000000      0.000000       0.000000\n",
            "50%        3.000000      0.000000       2.000000\n",
            "75%        4.000000      0.000000      16.000000\n",
            "max        5.000000    150.000000     607.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Missing value information\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"\\nMissing Value Information:\")\n",
        "print(missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Mw70ozt6yMG",
        "outputId": "f5a3dc0b-a248-43cb-b53f-431ec5221cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing Value Information:\n",
            "published_date           0\n",
            "list_name                0\n",
            "list_name_encoded        0\n",
            "rank                     0\n",
            "isbn13                   4\n",
            "isbn10                1284\n",
            "title                    0\n",
            "author                  69\n",
            "description           8119\n",
            "amazon_product_url       0\n",
            "price                    0\n",
            "weeks_on_list            0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Other relevant information\n",
        "print(\"\\nNumber of unique authors:\", df['author'].nunique())\n",
        "print(\"Number of unique titles:\", df['title'].nunique())\n",
        "print(\"Number of unique list names:\", df['list_name'].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6na4foE61tS",
        "outputId": "6919fd56-fb5f-4877-b51a-7ebeeb0f9209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of unique authors: 3609\n",
            "Number of unique titles: 6577\n",
            "Number of unique list names: 59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCSLIafaEGVK"
      },
      "source": [
        "# Data Wrangling\n",
        "Create a subset of your original data and perform the following.  \n",
        "\n",
        "1. Modify multiple column names.\n",
        "\n",
        "2. Look at the structure of your data – are any variables improperly coded? Such as strings or characters? Convert to correct structure if needed.\n",
        "\n",
        "3. Fix missing and invalid values in data.\n",
        "\n",
        "4. Create new columns based on existing columns or calculations.\n",
        "\n",
        "5. Drop column(s) from your dataset.\n",
        "\n",
        "6. Drop a row(s) from your dataset.\n",
        "\n",
        "7. Sort your data based on multiple variables.\n",
        "\n",
        "8. Filter your data based on some condition.\n",
        "\n",
        "9. Convert all the string values to upper or lower cases in one column.\n",
        "\n",
        "10. Check whether numeric values are present in a given column of your dataframe.\n",
        "\n",
        "11. Group your dataset by one column, and get the mean, min, and max values by group.\n",
        "  * Groupby()\n",
        "  * agg() or .apply()\n",
        "\n",
        "12. Group your dataset by two columns and then sort the aggregated results within the groups.\n",
        "\n",
        "**You are free (and should) to add on to these questions.  Please clearly indicate in your assignment your answers to these questions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VWWvvynEiQT"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nATPKSaNXD9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions  \n",
        "\n",
        "After exploring your dataset, provide a short summary of what you noticed from this dataset.  What would you explore further with more time?"
      ],
      "metadata": {
        "id": "tujjevRpXEen"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SshtuQj9XR5_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}